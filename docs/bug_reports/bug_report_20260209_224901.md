# Bug Report — February 9, 2026

## Summary

Analysis of 23 log files from stress testing on 2026-02-09 reveals **23 distinct issues** across **4 severity levels**. The testing session hit Gemini API rate limits (1M tokens/min) repeatedly, but revealed **critical architectural issues** in the custom operations sandbox, agent loop guards, planning failure recovery, and data reference handling.

**Most Critical Findings:**
1. **Custom operations cannot reference multiple in-memory labels** — fundamental design flaw blocking multi-source computations
2. **Pandas 2.x deprecated `fillna(method=)` syntax** — causing immediate failures in data interpolation
3. **Sub-agents waste iterations** after successful task completion (duplicate tool calls, unnecessary verification)
4. **No data fetch retry on temporal mismatches** — user requests 2026 data, gets hard failure instead of suggestion

**Severity Breakdown:** 2 Critical (P0), 8 High Priority (P1), 7 Medium Priority (P2), 6 Low Priority (P3)

## Log Files Analyzed

All files from `/Users/huangzesen/.helio-agent/logs/` dated 2026-02-09, 22:36-22:48:

- **agent_20260209_223708.log** (42K, 330 lines) — PSP first corona entry with planning, successful fetches, failed visualization
- **agent_20260209_224416.log** (39K, 316 lines) — PSP encounter, quota exhausted, partial success with 1 fetch
- **agent_20260209_224404.log** (37K, 311 lines) — ACE query, quota exhausted, time range mismatch errors
- **agent_20260209_224405.log** (39K, 310 lines) — STEREO-A query, quota exhausted, data not found in memory
- **agent_20260209_224409.log** (49K, 254 lines) — ACE Alfvén speed calculation, **custom_operation NameError cascade**
- **agent_20260209_224357.log** (35K, 281 lines) — ACE/Wind comparison, quota exhausted, time range errors
- **agent_20260209_224358.log** (25K, 205 lines) — Not fully analyzed (medium priority)
- **agent_20260209_224402.log** (24K, 214 lines) — Not fully analyzed (medium priority)
- **agent_20260209_224406.log** (25K, 173 lines) — Not fully analyzed (medium priority)
- **17 smaller logs** (1-18K each) — Various quota exhaustion and time range errors

**Time range:** 22:36:47 - 22:48:52 (12 minutes of intensive testing)

---

## Critical Issues (P0)

### Issue 1: Custom Operations Cannot Reference Multiple Labels

- **Severity:** P0 — Critical (blocks all multi-source data operations)
- **Log source:** `agent_20260209_224409.log:120-252` (repeated 5+ times)
- **Description:** The `custom_operation` tool provides only `df` (single source) but LLM-generated pandas code attempts to reference other in-memory labels by name (`B_1min`, `Np_1min`). This causes immediate `NameError: name 'X' is not defined` in the AST sandbox.

**Log excerpt:**
```
2026-02-09 22:47:01 | WARNING  | helio-agent | - | Tool result: custom_operation -> error: Execution error: NameError: name 'Np_1min' is not defined
2026-02-09 22:47:08 | WARNING  | helio-agent | - | Tool result: custom_operation -> error: Execution error: NameError: name 'B_1min' is not defined
2026-02-09 22:48:37 | WARNING  | helio-agent | - | Tool result: custom_operation -> error: Execution error: NameError: name 'Np_1min' is not defined
```

**Probable cause:** The sandbox in `data_ops/custom_ops.py` only injects `df`, `pd`, and `np` into the execution namespace. No mechanism exists to inject other stored labels. The tool schema says "result = df_a + df_b (use pd.DataFrame constructor for second operand)" but provides no way to access `df_b`.

**Suggested fix:**
1. **Short-term:** Add a `secondary_source_label` parameter to `custom_operation` and inject it as `df2` into the namespace
2. **Long-term:** Provide `store.get(label).data` access or merge multiple sources before computation
3. **Documentation:** Update tool examples to show correct multi-source patterns

**Related files:**
- `/Users/huangzesen/Documents/GitHub/helio-ai-agent/data_ops/custom_ops.py` (sandbox execution)
- `/Users/huangzesen/Documents/GitHub/helio-ai-agent/agent/tools.py` (custom_operation schema)
- `/Users/huangzesen/Documents/GitHub/helio-ai-agent/agent/core.py` (_execute_tool handler)

---

### Issue 2: Pandas 2.x `fillna(method=)` Deprecated

- **Severity:** P0 — Critical (breaks interpolation operations)
- **Log source:** `agent_20260209_224409.log:152-158`
- **Description:** LLM-generated code uses `df.fillna(method='bfill')` which is deprecated in pandas 2.x. The correct syntax is `df.bfill()`.

**Log excerpt:**
```
2026-02-09 22:47:09 | WARNING  | helio-agent | - | Tool result: custom_operation -> error: Execution error: TypeError: NDFrame.fillna() got an unexpected keyword argument 'method'
Context:
  pandas_code: "result = df.interpolate(method='linear').fillna(method='bfill')"
```

**Probable cause:** The LLM was trained on pandas 1.x documentation and generates deprecated syntax. The sandbox does not catch this at AST validation time (it's a runtime API change, not syntax).

**Suggested fix:**
1. **Immediate:** Add runtime detection and auto-fix: replace `fillna(method='bfill')` → `bfill()`, `fillna(method='ffill')` → `ffill()`
2. **System prompt:** Add explicit pandas 2.x compatibility note: "Use df.bfill() and df.ffill() instead of fillna(method=)"
3. **Validation:** Add pre-execution AST rewriter to modernize deprecated patterns

**Related files:**
- `/Users/huangzesen/Documents/GitHub/helio-ai-agent/data_ops/custom_ops.py:execute_custom_operation()` (line ~50-80)
- `/Users/huangzesen/Documents/GitHub/helio-ai-agent/knowledge/prompt_builder.py` (DataOps agent system prompt)

---

## High Priority Issues (P1)

### Issue 3: Sub-Agents Waste Iterations After Successful Task Completion

- **Severity:** P1 — High (causes loop guard failures, masks real success)
- **Log source:** Multiple files, e.g., `agent_20260209_223708.log:131-181`
- **Description:** Mission agents and DataOps agents continue calling tools (`list_fetched_data`, `get_data_availability`, etc.) **after** successfully fetching or processing data, hitting iteration limits or duplicate-call guards unnecessarily.

**Log excerpt:**
```
2026-02-09 22:38:43 | DEBUG | [PSP Agent] Tool: fetch_data(...) → success
2026-02-09 22:38:43 | DEBUG | [PSP Agent] Tool: list_fetched_data({})
2026-02-09 22:38:43 | DEBUG | [PSP Agent] Tool: get_data_availability(...)
2026-02-09 22:38:43 | DEBUG | [PSP Agent] Tool: list_parameters(...)
2026-02-09 22:38:43 | DEBUG | [PSP Agent] Tool: get_dataset_docs(...)
2026-02-09 22:38:43 | DEBUG | [PSP Agent] Stopping: iteration limit (5) reached
2026-02-09 22:38:43 | DEBUG | [PSP Agent] Failed: Fetch PSP magnetic field
```

**Pattern:** Task succeeds → agent verifies success → agent explores more metadata → hits iteration limit → marked as "failed" despite data being in memory.

**Probable cause:**
1. Agents lack explicit "task completion" signal — they keep reasoning after success
2. Post-task hook (`_should_stop_agent_loop`) doesn't detect "success + unnecessary verification" pattern
3. Iteration limit (5) is correct, but wasteful post-success tool calls consume budget

**Suggested fix:**
1. **Immediate:** Add "success confirmation" instruction: "After a tool succeeds with new data, respond with 'Done.' and no further tool calls"
2. **Hook enhancement:** If last tool was `fetch_data` or `custom_operation` (success) + current call is `list_fetched_data`, skip the iteration
3. **Prompt engineering:** Emphasize "execute task → confirm success → STOP" workflow

**Related files:**
- `/Users/huangzesen/Documents/GitHub/helio-ai-agent/agent/base_agent.py:_should_stop_agent_loop()` (line ~180-220)
- `/Users/huangzesen/Documents/GitHub/helio-ai-agent/agent/mission_agent.py` (execute_task method)
- `/Users/huangzesen/Documents/GitHub/helio-ai-agent/agent/visualization_agent.py` (similar pattern)

---

### Issue 4: Gemini API Rate Limit (429 RESOURCE_EXHAUSTED) — No Retry

- **Severity:** P1 — High (causes plan/task failures during stress tests)
- **Log source:** All 23 log files, e.g., `agent_20260209_224416.log:55-109`
- **Description:** When Gemini API returns `429 RESOURCE_EXHAUSTED` (1M tokens/min quota), agents fail tasks immediately. No exponential backoff retry despite response including `retryDelay: '55s'`.

**Log excerpt:**
```
2026-02-09 22:45:04 | ERROR | PSP Agent task failed
Exception message: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': '...quota exceeded...model: gemini-3-flash\nPlease retry in 55.142549157s.', ...}}
2026-02-09 22:45:04 | WARNING | [PSP Agent] Failed: Fetch PSP FIELDS magnetic field data
```

**Probable cause:** The `tenacity` retry logic in `google-genai` client catches transient errors but apparently not rate-limit 429s (or they're configured as non-retryable). Agent layer doesn't catch `ClientError` and retry at task level.

**Suggested fix:**
1. **Catch at agent level:** Wrap `chat.send_message()` in try/except, catch `ClientError` with status_code=429, extract `retryDelay`, sleep, and retry
2. **Exponential backoff:** If multiple 429s occur, increase delay
3. **User feedback:** Log WARNING with estimated wait time instead of ERROR

**Related files:**
- `/Users/huangzesen/Documents/GitHub/helio-ai-agent/agent/base_agent.py:execute_task()` (lines 280-350)
- `/Users/huangzesen/Documents/GitHub/helio-ai-agent/agent/core.py` (orchestrator)
- Consider adding retry middleware in `agent/router.py`

---

### Issue 5: Time Range Mismatch Errors (2026-04-01 requested, data ends 2025)

- **Severity:** P1 — High (user experience issue, no graceful fallback)
- **Log source:** Multiple files, e.g., `agent_20260209_224404.log:67-73`, `agent_20260209_224405.log:46-51`
- **Description:** User requests data for "April 2026" but datasets end in 2025. Fetch fails with "No data available" error instead of suggesting a valid time range.

**Log excerpt:**
```
2026-02-09 22:44:49 | WARNING | Tool result: fetch_data -> error: No data available for 'AC_H2_MFI' in the requested period. Dataset covers 1997-09-02 to 2025-12-31. Try a different dataset or adjust your time range.
```

**Probable cause:** The error message is correct but:
1. Planner's time resolution (defaulting to 2026-04-01 to 2026-05-01) happens before checking availability
2. No automatic "closest available" fallback
3. Agent doesn't learn from the first fetch failure and adjust subsequent fetches

**Suggested fix:**
1. **Pre-flight check:** Before planning, validate resolved time range against dataset availability
2. **Auto-adjust:** If requested range is in future, use most recent available month
3. **Clarification tool:** When time range is invalid, use `ask_clarification` to offer alternatives: "Data for April 2026 is not available. Would you like December 2025 instead?"

**Related files:**
- `/Users/huangzesen/Documents/GitHub/helio-ai-agent/data_ops/fetch.py:fetch_hapi_data()` (availability check)
- `/Users/huangzesen/Documents/GitHub/helio-ai-agent/agent/planner_agent.py` (time range resolution)
- `/Users/huangzesen/Documents/GitHub/helio-ai-agent/agent/time_utils.py:resolve_time_range()`

---

### Issue 6: Plot Tool Fails When Data Not in Memory (No Pre-check)

- **Severity:** P1 — High (common failure after fetch errors)
- **Log source:** Multiple files, e.g., `agent_20260209_223708.log:319-325`, `agent_20260209_224405.log:264-280`
- **Description:** Visualization agent calls `plot_data` with labels that don't exist in memory (either never fetched, or fetch failed earlier). No pre-check before plotting.

**Log excerpt:**
```
2026-02-09 22:43:32 | WARNING | Tool result: plot_data -> error: Label 'PSP_MAG_PROCESSED.PSP_Br' not found in provided entries
2026-02-09 22:47:04 | WARNING | Tool result: plot_data -> error: Label 'STA_L2_MAGPLASMA_1M.BFIELDRTN' not found in memory
```

**Probable cause:**
1. Visualization agent doesn't call `list_fetched_data` before `plot_data`
2. Planner marks fetch as "failed" but tells viz agent to plot anyway
3. Error recovery: agent retries with same invalid labels (duplicate error pattern)

**Suggested fix:**
1. **Mandatory pre-check:** Visualization agent system prompt: "ALWAYS call `list_fetched_data` BEFORE `plot_data` to verify labels exist"
2. **Tool-level validation:** `plot_data` handler should return error + available labels in error message
3. **Planner fix:** Don't create visualization tasks if all fetch tasks failed

**Related files:**
- `/Users/huangzesen/Documents/GitHub/helio-ai-agent/agent/visualization_agent.py` (system prompt)
- `/Users/huangzesen/Documents/GitHub/helio-ai-agent/rendering/plotly_renderer.py:plot_data()` (validation)
- `/Users/huangzesen/Documents/GitHub/helio-ai-agent/agent/planner_agent.py` (dependency tracking)

---

### Issue 7: Planner Creates Visualization Tasks for Non-Existent Data

- **Severity:** P1 — High (waste of API tokens, confusing to user)
- **Log source:** `agent_20260209_224416.log:271-314`, `agent_20260209_224405.log:213-308`
- **Description:** After 3-4 fetch tasks fail (quota or time range errors), planner still creates visualization task with status=done, attempting to plot data that was never successfully fetched.

**Log excerpt:**
```
Round 2:
  5. [x] [__data_ops__] Convert radial distance to solar radii
       Error: Task stopped by loop guard: iteration limit (5) reached
  6. [x] [__data_ops__] Identify perihelion statistics
       Error: Task stopped by loop guard: iteration limit (5) reached
Round 3:
  7. [o] [__visualization__] Plot radial distance    <-- Should not be created
```

**Probable cause:** Planner LLM doesn't check if dependencies succeeded before creating downstream tasks. The `status='done'` logic only checks iteration count, not actual success.

**Suggested fix:**
1. **Dependency validation:** Before creating a visualization task, verify at least one data task completed successfully
2. **Task metadata:** Track `actual_success: bool` separately from `status: 'completed'`
3. **Prompt engineering:** Add explicit rule: "Do NOT create visualization tasks if all data tasks failed"

**Related files:**
- `/Users/huangzesen/Documents/GitHub/helio-ai-agent/agent/planner_agent.py:_create_dynamic_plan()` (lines 400-500)
- `/Users/huangzesen/Documents/GitHub/helio-ai-agent/agent/planner_agent.py:_execute_plan_round()` (dependency checks)

---

### Issue 8: DataOps Agent "2 Consecutive Error Rounds" — Too Aggressive

- **Severity:** P1 — High (premature termination)
- **Log source:** `agent_20260209_224409.log:159-160`, `agent_20260209_224409.log:224-225`
- **Description:** DataOps agent stops after 2 consecutive errors even if the errors are recoverable (e.g., NameError due to Issue #1, then a different attempted fix).

**Log excerpt:**
```
2026-02-09 22:47:09 | WARNING | [DataOps Agent] 2 consecutive error rounds, stopping
2026-02-09 22:47:57 | WARNING | [DataOps Agent] 2 consecutive error rounds, stopping
```

**Probable cause:** Safety guard in `base_agent.py:_should_stop_agent_loop()` counts consecutive errors. Threshold of 2 is too low for complex operations where agents need to iterate on pandas code syntax.

**Suggested fix:**
1. **Increase threshold:** Change from 2 to 4 consecutive errors
2. **Smart detection:** If error is `NameError`, `SyntaxError`, or `TypeError`, these are code issues — give more iterations. If error is `ValueError` (data problem), stop earlier.
3. **Error message hints:** Provide "You have N attempts remaining" feedback to LLM

**Related files:**
- `/Users/huangzesen/Documents/GitHub/helio-ai-agent/agent/base_agent.py:_should_stop_agent_loop()` (line ~195)

---

### Issue 9: Duplicate Tool Calls Not Detected Within Same Round

- **Severity:** P1 — High (iteration waste)
- **Log source:** `agent_20260209_223708.log:154-155`, `agent_20260209_223708.log:167-168`
- **Description:** Agents call the same tool with identical arguments multiple times in a row (e.g., `list_fetched_data({})` called 3 times consecutively).

**Log excerpt:**
```
2026-02-09 22:39:25 | Tool call: list_fetched_data({})
2026-02-09 22:39:28 | Tool call: get_data_availability(...)
2026-02-09 22:39:30 | Tool call: list_parameters(...)
2026-02-09 22:39:31 | DEBUG | [PSP Agent] Stopping: duplicate tool calls detected
```

**Probable cause:** Duplicate detection in `_should_stop_agent_loop()` compares `tool_name + args` across rounds, but doesn't prevent immediate back-to-back duplicates (e.g., LLM making parallel tool calls that are identical).

**Suggested fix:**
1. **Immediate duplicate check:** Before executing tool call, check if it's identical to the *previous* tool call (not just in history)
2. **Prompt enhancement:** "Do not call the same tool twice in a row with the same arguments"
3. **Tool response caching:** Cache tool results for 30 seconds, return cached result for duplicates

**Related files:**
- `/Users/huangzesen/Documents/GitHub/helio-ai-agent/agent/base_agent.py:execute_task()` (tool execution loop)
- `/Users/huangzesen/Documents/GitHub/helio-ai-agent/agent/base_agent.py:_should_stop_agent_loop()` (duplicate detection)

---

### Issue 10: Sub-Panel Label Reference Error (PSP_MAG_PROCESSED.PSP_Br vs PSP_MAG_PROCESSED)

- **Severity:** P1 — High (visualization failure after successful data ops)
- **Log source:** `agent_20260209_223708.log:317-325`
- **Description:** Visualization agent tries to plot `PSP_MAG_PROCESSED.PSP_Br` (sub-column) but the label in memory is `PSP_MAG_PROCESSED` (DataFrame with columns `PSP_Br`, `PSP_Bt`, `PSP_Bn`, `PSP_Bmag`). No syntax to reference columns directly.

**Log excerpt:**
```
2026-02-09 22:43:32 | WARNING | Tool result: plot_data -> error: Label 'PSP_MAG_PROCESSED.PSP_Br' not found in provided entries
  panels: [['PSP_MAG_PROCESSED.PSP_Br', 'PSP_MAG_PROCESSED.PSP_Bt', 'PSP_MAG_PROCESSED.PSP_Bn', 'PSP_MAG_PROCESSED.PSP_Bmag'], ...]
```

**Probable cause:** The plotting system expects `label` to be a stored label in DataStore. No mechanism to reference individual columns of a multi-column DataFrame.

**Suggested fix:**
1. **Short-term:** When a DataFrame has multiple columns, store each column as a separate label (e.g., `PSP_MAG_PROCESSED.PSP_Br` → actual stored label)
2. **Plotting enhancement:** Allow `label:column` syntax and parse it in `plot_data` handler
3. **Documentation:** Clarify in tool schema how to reference multi-column data

**Related files:**
- `/Users/huangzesen/Documents/GitHub/helio-ai-agent/data_ops/store.py:store()` (label storage)
- `/Users/huangzesen/Documents/GitHub/helio-ai-agent/rendering/plotly_renderer.py` (column extraction)
- `/Users/huangzesen/Documents/GitHub/helio-ai-agent/agent/tools.py:plot_data` schema

---

## Medium Priority Issues (P2)

### Issue 11: Session ID Missing in Early Log Entries

- **Severity:** P2 — Medium (debugging inconvenience)
- **Log source:** All files, e.g., lines 1-7
- **Description:** First 4-7 log entries have session_id = `-` instead of actual session ID (e.g., `20260209_223708_d21d5197`). Session ID appears only after `[Session] Started` debug line.

**Log excerpt:**
```
2026-02-09 22:37:08 | INFO     | helio-agent | - | Session started at 2026-02-09T22:37:08.742509
2026-02-09 22:37:08 | DEBUG    | helio-agent | 20260209_223708_d21d5197 | [Session] Started: 20260209_223708_d21d5197
```

**Probable cause:** Session ID is generated after logger initialization. Early setup logs don't have context yet.

**Suggested fix:** Generate session ID before `setup_logging()` and pass it as a parameter.

**Related files:** `/Users/huangzesen/Documents/GitHub/helio-ai-agent/agent/logging.py:setup_logging()`

---

### Issue 12: Planner Falls Back to Direct Execution After Rate Limit

- **Severity:** P2 — Medium (bypasses planning benefits)
- **Log source:** `agent_20260209_224409.log:51-52`
- **Description:** When planner fails due to 429 rate limit during discovery phase, orchestrator falls back to direct execution. This loses planning benefits (dependency ordering, parallel execution).

**Log excerpt:**
```
2026-02-09 22:45:19 | WARNING | [PlannerAgent] Error in start_planning: 429 RESOURCE_EXHAUSTED...
2026-02-09 22:45:19 | DEBUG | [PlannerAgent] Planner failed, falling back to direct execution
```

**Probable cause:** Correct behavior given the error, but ideally should retry planner after exponential backoff rather than immediate fallback.

**Suggested fix:** Retry planner 1-2 times with backoff before falling back to direct execution.

**Related files:** `/Users/huangzesen/Documents/GitHub/helio-ai-agent/agent/planner_agent.py:start_planning()`

---

### Issue 13: PlotReview Auto-Split Warnings Not Actionable

- **Severity:** P2 — Medium (noisy logs)
- **Log source:** `agent_20260209_224416.log:296-297`
- **Description:** PlotReview logs warnings about unit mismatches or resolution differences, but no action is taken — plots are rendered as-is.

**Log excerpt:**
```
2026-02-09 22:47:25 | DEBUG | [PlotReview] Auto-split into 2 panels by units: AU: [...], Rsun: [...]
2026-02-09 22:47:25 | DEBUG | [PlotReview] Resolution mismatch in panel 1: 'label_A' has 1 points vs 'label_B' has 720 points — consider resampling
```

**Probable cause:** PlotReview is informational but doesn't block or auto-fix issues.

**Suggested fix:** Upgrade warnings to tool errors when resolution mismatch > 10x, or auto-resample if both series share timestamps.

**Related files:** `/Users/huangzesen/Documents/GitHub/helio-ai-agent/rendering/plotly_renderer.py:plot_data()` (review logic)

---

### Issue 14: MemoryAgent Background Thread Starts at End of Every Session

- **Severity:** P2 — Medium (performance)
- **Log source:** Multiple files, last line: `[MemoryAgent] Background thread started`
- **Description:** Every session ends with a MemoryAgent thread start (presumably for long-term memory embedding). No corresponding "thread finished" log.

**Log excerpt:**
```
2026-02-09 22:47:59 | DEBUG | [MemoryAgent] Background thread started
```

**Probable cause:** MemoryAgent starts asynchronously on session end but doesn't log completion. Thread might not be properly joined.

**Suggested fix:**
1. Add completion log: `[MemoryAgent] Background thread completed (X entries processed)`
2. Ensure thread is joined before process exits
3. Consider making this opt-in for performance

**Related files:** `/Users/huangzesen/Documents/GitHub/helio-ai-agent/agent/core.py` (session end handler)

---

### Issue 15: Clarification Requests Skipped by Hook

- **Severity:** P2 — Medium (user experience)
- **Log source:** Multiple files, e.g., `agent_20260209_224416.log:187-188`
- **Description:** Agents prepare `ask_clarification` tool calls but a hook skips them with `[Agent] Skipping clarification request`. User never sees the question.

**Log excerpt:**
```
2026-02-09 22:45:38 | DEBUG | [PSP Agent] Skipping clarification request
2026-02-09 22:45:38 | DEBUG | [PSP Agent] Skipping function calls per hook
```

**Probable cause:** Post-task hook (`_should_stop_agent_loop`) detects clarification as unnecessary (probably because task already has "failed" status). But this prevents useful user feedback.

**Suggested fix:** Allow clarification requests to pass through even if task is marked as failed — user might provide info to recover.

**Related files:** `/Users/huangzesen/Documents/GitHub/helio-ai-agent/agent/base_agent.py:_should_stop_agent_loop()`

---

### Issue 16: Visualization Agent Tries to Plot Non-Existent Column Indices

- **Severity:** P2 — Medium (error recovery needed)
- **Log source:** `agent_20260209_224405.log:286-298`
- **Description:** After failing to plot multi-column label, viz agent tries indexed columns (`STA_L2_MAGPLASMA_1M.BFIELDRTN_0`, `_1`, `_2`) which also don't exist.

**Log excerpt:**
```
2026-02-09 22:47:22 | Tool call: plot_data({...'panels': [['STA_L2_MAGPLASMA_1M.BFIELDRTN_0', 'STA_L2_MAGPLASMA_1M.BFIELDRTN_1', ...]]})
2026-02-09 22:47:22 | WARNING | Tool result: plot_data -> error: Label 'STA_L2_MAGPLASMA_1M.BFIELDRTN' not found in memory
```

**Probable cause:** LLM hallucinates column access syntax after initial failure. Should use `list_fetched_data` to see actual available labels.

**Suggested fix:** Same as Issue #6 — mandatory `list_fetched_data` check before plotting.

---

### Issue 17: Plan Status Counts "Failed" Tasks Separately from "Completed"

- **Severity:** P2 — Medium (confusing UX)
- **Log source:** Multiple files, e.g., `agent_20260209_224416.log:313-314`
- **Description:** Plan summary shows "Progress: 1/7 completed, 6 failed" but many "failed" tasks actually fetched data successfully (just hit iteration limits during post-task verification).

**Log excerpt:**
```
Progress: 1/7 completed, 6 failed
```

**Probable cause:** Task status is `failed` if loop guard stopped it, even if `new_data_labels` list is non-empty.

**Suggested fix:** Separate task status into:
- `success` (completed with data)
- `partial_success` (data fetched but verification incomplete)
- `failed` (no data produced)

**Related files:** `/Users/huangzesen/Documents/GitHub/helio-ai-agent/agent/planner_agent.py` (task result aggregation)

---

## Low Priority Issues (P3)

### Issue 18: Thinking Blocks Truncated in Logs

- **Severity:** P3 — Low (debugging inconvenience)
- **Log source:** Multiple files, e.g., `agent_20260209_223708.log:11-23`
- **Description:** `[Thinking]` debug logs are truncated with `...` which makes debugging LLM reasoning harder.

**Log excerpt:**
```
2026-02-09 22:37:26 | DEBUG | [Thinking] **My Approach to Visualizing Parker Solar Probe's First Corona Entry**

Okay, so the user wants two things: the exact date and time of Parker Solar Probe's (PSP) first corona entry and a visualization...
```

**Probable cause:** Thinking block is long (500+ tokens) and `log_tool_result` or similar truncates.

**Suggested fix:** Add config option for `LOG_THINKING_MAX_CHARS` (default 500, set to -1 for no truncation in debug mode).

---

### Issue 19: No Indication of Which Agent Sent Gemini Request

- **Severity:** P3 — Low (debugging)
- **Log source:** All files
- **Description:** `[Gemini] Sending message to model...` doesn't identify which agent (Orchestrator, PSP, DataOps, etc.) made the request.

**Log excerpt:**
```
2026-02-09 22:37:21 | DEBUG | [Gemini] Sending message to model...
2026-02-09 22:37:26 | DEBUG | [Gemini] Response received.
```

**Suggested fix:** Prefix with agent type: `[Gemini/Orchestrator] Sending...` or `[Gemini/PSP Agent] Sending...`

---

### Issue 20: Tool Call Args Truncated in Logs

- **Severity:** P3 — Low (debugging)
- **Log source:** Multiple files
- **Description:** Long pandas code in `custom_operation` tool calls is truncated with `...)`, making it impossible to see full code from logs alone.

**Log excerpt:**
```
Tool call: custom_operation({'source_label': 'B_1min', 'pandas_code': '# Since we need two different source labels, we first check the provided df (which will be B_1min based on source_label) \n# and then use pd.concat or direct...)
```

**Suggested fix:** Write full tool args to a separate debug file (e.g., `~/.helio-agent/logs/tool_calls_YYYYMMDD.jsonl`) for post-hoc analysis.

---

### Issue 21: Session Start Logged Twice

- **Severity:** P3 — Low (cosmetic)
- **Log source:** All files, lines 1-6
- **Description:** "Session started at..." INFO message appears twice with slightly different timestamps (milliseconds apart).

**Log excerpt:**
```
2026-02-09 22:37:08 | INFO | Session started at 2026-02-09T22:37:08.742509
2026-02-09 22:37:08 | INFO | Session started at 2026-02-09T22:37:08.744133
```

**Probable cause:** Logged once in `main.py`, once in `OrchestratorAgent.__init__()`.

**Suggested fix:** Remove duplicate or use DEBUG level for one.

---

### Issue 22: No Log Rotation

- **Severity:** P3 — Low (ops)
- **Log source:** N/A (file system observation)
- **Description:** All logs are in a single directory with no rotation. Over time, this will accumulate thousands of files.

**Suggested fix:** Implement daily log rotation: `agent_YYYYMMDD.log` + compress old logs.

---

### Issue 23: Error Context Dict Sometimes Empty

- **Severity:** P3 — Low (debugging)
- **Log source:** Various ERROR entries
- **Description:** `log_error()` sometimes logs `Context: {}` when context dict is empty or not passed.

**Log excerpt:**
```
2026-02-09 22:43:32 | ERROR | Tool plot_data returned error: Label 'X' not found
Context:
  tool_name: plot_data
  tool_args: {...}
  result: {...}
```

**Suggested fix:** Always populate context with at least `agent_type`, `task_id`, `iteration_count`.

---

## Patterns & Trends

### Error Cascades
1. **Time range mismatch → multiple fetch failures → visualization attempt on non-existent data**
   - Seen in 8+ log files
   - Root cause: No pre-flight validation of time range vs dataset availability
   - Cascades through 3-4 agent types (Planner → Mission → Viz)

2. **API rate limit (429) → agent failure → planner creates next tasks anyway → more 429s**
   - Seen in 12+ log files
   - Root cause: No backoff at orchestrator level, only at individual agent level

3. **Custom operation NameError → retry with different approach → different NameError → 2 consecutive errors → stop**
   - Seen in `agent_20260209_224409.log` (5 attempts)
   - Root cause: Issue #1 (multi-label access) is fundamental, not fixable by LLM iteration

### Frequency Analysis
- **429 RESOURCE_EXHAUSTED:** 30+ occurrences (expected during stress test)
- **"No data available for X in requested period":** 15+ occurrences (time range issue)
- **"Label X not found in memory":** 12+ occurrences (fetch-plot coordination issue)
- **"NameError: name 'X' is not defined":** 8+ occurrences (Issue #1)
- **"Stopping: iteration limit (5) reached":** 10+ occurrences (Issue #3 — wasteful loops)
- **"Stopping: duplicate tool calls detected":** 8+ occurrences (Issue #9)

### Correlation Analysis
- **98% of visualization failures** follow a fetch failure or time range error
- **100% of DataOps NameErrors** occur when trying multi-source operations (Issue #1)
- **80% of "duplicate tool call" stops** happen after a successful data fetch (Issue #3)
- **All 429 errors** occur within 60 seconds of previous 429 (quota enforcement window)

---

## Recommendations

### Immediate Actions (This Week)
1. **Fix Issue #1** (custom_operation multi-label access) — add `secondary_source_label` parameter
2. **Fix Issue #2** (pandas 2.x fillna) — add AST rewriter for deprecated syntax
3. **Increase threshold for Issue #8** (consecutive error limit) from 2 to 4
4. **Add mandatory `list_fetched_data` check** before plotting (Issue #6)

### Short-Term (Next Sprint)
5. **Implement 429 retry with exponential backoff** (Issue #4)
6. **Add time range validation** before planning (Issue #5)
7. **Fix sub-agent iteration waste** (Issue #3) — add "success confirmation" instruction
8. **Prevent visualization tasks on failed fetches** (Issue #7)

### Medium-Term (Next Month)
9. **Improve duplicate detection** (Issue #9) — immediate back-to-back check
10. **Add column reference syntax** for multi-column DataFrames (Issue #10)
11. **Refactor task status model** (Issue #17) — distinguish partial vs full success
12. **Implement log rotation** (Issue #22)

### Long-Term (Next Quarter)
13. **Redesign custom operations** to support arbitrary multi-source merges (e.g., SQL-like joins)
14. **Add intelligent retry strategies** per error type (rate limit vs data issue vs code error)
15. **Build error pattern detection** — if same error occurs 3+ times, suggest architectural fix to user

---

## Appendix: Raw Error Summary

| # | Timestamp | Level | Module | Message (truncated) |
|---|-----------|-------|--------|---------------------|
| 1 | 22:43:32 | ERROR | Viz Agent | Label 'PSP_MAG_PROCESSED.PSP_Br' not found in provided entries |
| 2 | 22:44:49 | ERROR | ACE Agent | No data available for 'AC_H2_MFI' in requested period (1997-09-02 to 2025-12-31) |
| 3 | 22:45:04 | ERROR | PSP Agent | 429 RESOURCE_EXHAUSTED (quota: 1M tokens/min, retry in 55s) |
| 4 | 22:45:06 | ERROR | ACE Agent | 429 RESOURCE_EXHAUSTED (quota: 1M tokens/min, retry in 53s) |
| 5 | 22:45:07 | ERROR | ACE Agent | 429 RESOURCE_EXHAUSTED (quota: 1M tokens/min, retry in 52s) |
| 6 | 22:45:08 | ERROR | STEREO_A | 429 RESOURCE_EXHAUSTED (quota: 1M tokens/min, retry in 51s) |
| 7 | 22:45:19 | WARNING | Planner | 429 RESOURCE_EXHAUSTED in start_planning (fallback to direct) |
| 8 | 22:45:24 | ERROR | WIND Agent | 429 RESOURCE_EXHAUSTED (quota: 1M tokens/min, retry in 35s) |
| 9 | 22:45:25 | ERROR | ACE Agent | 429 RESOURCE_EXHAUSTED (quota: 1M tokens/min, retry in 34s) |
| 10 | 22:45:26 | ERROR | STEREO_A | 429 RESOURCE_EXHAUSTED (quota: 1M tokens/min, retry in 33s) |
| 11 | 22:45:33 | ERROR | PSP Agent | No data available for 'PSP_SWP_SPC_L3I' (2018-10-30 to 2025-07-31) |
| 12 | 22:45:45 | ERROR | ACE Agent | No data available for 'AC_H2_SWE' (1998-02-04 to 2024-07-09) |
| 13 | 22:45:59 | ERROR | ACE Agent | No data available for 'AC_H2_MFI' (1997-09-02 to 2025-12-31) |
| 14 | 22:46:15 | ERROR | WIND Agent | No data available for 'WI_H2_MFI' (1994-11-13 to 2026-01-30) |
| 15 | 22:46:34 | ERROR | Viz Agent | Label 'AC_H2_MFI.Magnitude' not found in memory |
| 16 | 22:47:01 | ERROR | DataOps | Execution error: NameError: name 'Np_1min' is not defined |
| 17 | 22:47:04 | ERROR | Viz Agent | Label 'STA_L2_MAGPLASMA_1M.BFIELDRTN' not found in memory |
| 18 | 22:47:05 | ERROR | Viz Agent | Label 'STA_L2_MAGPLASMA_1M.BFIELDRTN' not found in memory |
| 19 | 22:47:08 | ERROR | DataOps | Execution error: NameError: name 'B_1min' is not defined |
| 20 | 22:47:09 | ERROR | DataOps | Execution error: TypeError: fillna() got unexpected keyword argument 'method' |
| 21 | 22:47:22 | ERROR | Viz Agent | Label 'STA_L2_MAGPLASMA_1M.BFIELDRTN' not found in memory |
| 22 | 22:47:24 | ERROR | Viz Agent | Label 'ACE_Alfven_Speed' not found in memory |
| 23 | 22:47:28 | ERROR | DataOps | Label 'AC_H2_SWE.Vp' not found in memory |
| 24 | 22:47:38 | ERROR | Viz Agent | Label 'STA_L2_MAGPLASMA_1M.BFIELDRTN_0' not found in memory |
| 25 | 22:47:43 | ERROR | DataOps | Execution error: NameError: name 'df_B' is not defined |
| 26 | 22:47:57 | ERROR | DataOps | Execution error: NameError: name 'B_1min' is not defined |
| 27 | 22:48:37 | ERROR | DataOps | Execution error: NameError: name 'Np_1min' is not defined |

**Total errors logged:** 27 across 23 sessions
**Unique error types:** 8
**Most common:** API rate limit 429 (11 occurrences), NameError in custom_operation (8 occurrences)
