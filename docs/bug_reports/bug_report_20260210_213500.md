# Bug Report — 2026-02-10 Session Analysis

## Summary
Analysis of session `agent_20260210_211534.log` (425 KB, 3024 lines, 222 tool calls) reveals **9 critical issues** affecting data quality, time range handling, and agent coordination. The session demonstrates persistent problems with:
- **Wrong time range handling** (agent fetched 2024-09-28 data, then tried to use it for 2025-06-16 analysis)
- **Silent all-NaN computation failure** (3 failed normalization attempts before success, agent didn't notice 0-point results)
- **Misleading error reporting** (sub-agent reports "failed" with NameError but simultaneously returns valid result with 8,585 points)
- **Excessive time range updates** (13 calls to `set_time_range` in a single session)

**Severity breakdown:** 2 P0 (critical), 4 P1 (high), 2 P2 (medium), 1 P3 (low)

## Log Files Analyzed
- **File:** `/Users/huangzesen/.helio-agent/logs/agent_20260210_211534.log`
- **Session ID:** `20260210_211534_b6a55908`
- **Date range:** 2026-02-10 21:15:34 to 21:33:45 (18 minutes)
- **Size:** 415.6 KB
- **Lines:** 3024
- **Total tool calls:** 222

## Critical Issues (P0)

### Issue 1: Time Range Mismatch Leading to All-NaN Normalization
- **Severity:** P0 — Critical
- **Log source:** Lines 2780-2906 (multiple occurrences)
- **Description:** Agent fetched `SUN_DIST` for 2024-09-28 to 2024-09-30 (from earlier PSP perihelion 21 analysis), then attempted to use it for normalizing magnetic field data from 2025-06-16 to 2025-06-22 (Encounter 24). Since the datasets had **zero temporal overlap**, the normalization produced all-NaN results. The agent executed **three failed normalization attempts** (producing 0 points each time) before correctly identifying the root cause.

- **Log excerpt:**
  ```
  2810: This temporal discrepancy is the likely explanation for why my `custom_operation` function
        is barfing all those NaNs when trying to compute `PSP_B_norm`. It's attempting to use
        distance data that's almost a year old relative to the magnetic field data, so there's
        no overlap.

  2900: [DataOps] Custom operation -> 'PSP_B_norm_fixed' (0 points)
  2906: [DataOps] Custom operation -> 'PSP_B_norm_fixed' (0 points)
  2922: [DataOps] Custom operation -> 'PSP_B_norm_fixed' (8585 points)  # Finally succeeded
  ```

- **Probable cause:**
  1. Data store retains labels from previous requests without expiry
  2. Agent doesn't validate time range overlap before attempting multi-source operations
  3. `custom_operation` tool doesn't warn when result is empty/all-NaN
  4. Agent reasoning mentions "barfing all those NaNs" but took 3 attempts to fix

- **Suggested fix:**
  1. **Immediate:** Add validation in `custom_operation` tool to check temporal overlap of source datasets and warn if <10% overlap
  2. **Short-term:** Log WARNING when computed result has 0 valid points
  3. **Medium-term:** Add `time_range` filter parameter to `custom_operation` to ensure slice alignment
  4. **Long-term:** Implement automatic label versioning (e.g., `SUN_DIST_20240928`, `SUN_DIST_20250616`) to prevent reuse confusion

- **Related files:** `agent/data_ops_agent.py`, `data_ops/custom_ops.py`, `data_ops/store.py`

### Issue 2: Sub-Agent Reports Failure with Valid Result
- **Severity:** P0 — Critical (data integrity)
- **Log source:** Lines 2889-2958
- **Description:** DataOps sub-agent returned status `error` with message `"NameError: name 'df_B_mag_val' is not defined"` BUT simultaneously returned a valid result with 8,585 data points and full statistics (mean: 1834.06 nT, range: 544-2465 nT). Orchestrator received contradictory signals: error status + success message.

- **Log excerpt:**
  ```
  2889: WARNING | Tool result: custom_operation -> error: Execution error: Execution error:
        NameError: name 'df_B_mag_val' is not defined
  2890: ERROR | Tool custom_operation returned error: ... NameError: name 'df_B_mag_val' is not defined
  ...
  2932: WARNING | Tool result: delegate_to_data_ops -> error: Sub-agent failed. Errors:
        custom_operation: ... NameError: name 'df_B_mag_val' is not defined

  2937: result: {'status': 'error', 'message': "Sub-agent failed. Errors: custom_operation: ...
        NameError: name 'df_B_mag_val' is not defined",
        'result': "I have computed the normalized magnetic field magnitude ...
                   **Data Points**: 8,585
                   **Time Range**: 2025-06-16 00:00:30 to 2025-06-21 23:59:30
                   **Mean**: 1,834.06 nT"}
  ```

- **Probable cause:**
  1. Sub-agent returns first tool error in `errors` list even when subsequent retries succeed
  2. Orchestrator checks `status == 'error'` before parsing `result` field
  3. Agent reasoning correctly identifies data exists: "list_fetched_data shows PSP_B_norm_fixed with 8,585 points"

- **Suggested fix:**
  1. **Immediate:** Fix sub-agent result aggregation to return `status: 'success'` if ANY tool call succeeded and produced data
  2. **Short-term:** Add `warnings` field separate from `errors` for non-fatal issues
  3. **Medium-term:** Change orchestrator to check for data presence in store, not just status field
  4. **Critical:** This is a **silent failure masking success** — dangerous for user trust

- **Related files:** `agent/core.py` (sub-agent delegation), `agent/data_ops_agent.py` (result aggregation)

## High Priority Issues (P1)

### Issue 3: Wrong Time Range — PSP Data Requested for 2012
- **Severity:** P1 — High
- **Log source:** Lines 880-888
- **Description:** PSP mission agent attempted to fetch magnetic field data for **2012-03-01 to 2012-04-01**, even though PSP launched in 2018. This is 6 years before mission start. Error caught by availability check but wastes API calls.

- **Log excerpt:**
  ```
  880: Tool call: fetch_data({'parameter_id': 'psp_fld_l2_mag_RTN_1min',
                               'time_range': '2012-03-01 to 2012-04-01',
                               'dataset_id': 'PSP_FLD_L2_MAG_RTN_1MIN'})
  882: WARNING | Tool result: fetch_data -> error: No data available for 'PSP_FLD_L2_MAG_RTN_1MIN'
                in the requested period. Dataset covers 2018-10-02 to 2025-07-31.
                Try a different dataset or adjust your time range.
  ```

- **Probable cause:**
  1. User likely said "PSP perihelion 21" or similar, but agent hallucinated date
  2. No mission-level validation of time range vs. launch date
  3. Planner time resolution likely resolved user's "last month" to current date, but PSP agent ignored it

- **Suggested fix:**
  1. **Immediate:** Add mission launch date validation in `fetch_data` tool BEFORE CDAWeb call
  2. **Short-term:** Log WARNING when requested time range predates mission start
  3. **Medium-term:** Add mission timeline context to prompts (e.g., "PSP launched 2018-08-12")

- **Related files:** `agent/mission_agent.py`, `knowledge/catalog.py`, `agent/time_utils.py`

### Issue 4: Plot Label Suffix Confusion (_0 vs _x)
- **Severity:** P1 — High
- **Log source:** Lines 1482-1503
- **Description:** Visualization agent tried two different label suffixes for vector component extraction without checking available labels first:
  - First attempt: `PSP_SWP_SPI_SF00_L3_MOM.VEL_RTN_SUN_0` (not found)
  - Second attempt: `PSP_SWP_SPI_SF00_L3_MOM.VEL_RTN_SUN_x` (not found)
  - Actual label in memory: `PSP_SWP_SPI_SF00_L3_MOM.VEL_RTN_SUN` (3-component vector, not pre-indexed)

- **Log excerpt:**
  ```
  1482: Tool: plot_data({'panels': [['PSP_Bmag'],
                                     ['PSP_SWP_SPI_SF00_L3_MOM.VEL_RTN_SUN_0'], ...])
  1485: WARNING | Tool result: plot_data -> error: Label 'PSP_SWP_SPI_SF00_L3_MOM.VEL_RTN_SUN_0'
                  not found in memory

  1493: Tool: plot_data({'panels': [['PSP_Bmag'],
                                     ['PSP_SWP_SPI_SF00_L3_MOM.VEL_RTN_SUN_x'], ...])
  1496: WARNING | Tool result: plot_data -> error: Label 'PSP_SWP_SPI_SF00_L3_MOM.VEL_RTN_SUN_x'
                  not found in provided entries

  1503: WARNING | [Visualization Agent] 2 consecutive error rounds, stopping
  ```

- **Probable cause:**
  1. Visualization agent doesn't call `list_fetched_data` to see actual label format
  2. Agent guesses component indexing convention (numeric `_0` vs letter `_x`) without verification
  3. Tool doesn't suggest similar labels when exact match fails

- **Suggested fix:**
  1. **Immediate:** Visualization agent MUST call `list_fetched_data` before first `plot_data` attempt
  2. **Short-term:** Implement fuzzy label matching in `plot_data` tool to suggest alternatives
  3. **Medium-term:** Add component extraction to `custom_operation` instead (e.g., `extract_component(label='VEL_RTN_SUN', component=0)`)

- **Related files:** `agent/visualization_agent.py`, `rendering/plotly_renderer.py`

### Issue 5: Variable Name Mismatch in Custom Operation Code
- **Severity:** P1 — High
- **Log source:** Line 2889
- **Description:** LLM-generated pandas code referenced `df_B_mag_val` but actual variable is `df_PSP_B_mag_val` (label prefix is added). This is the **multi-label NameError problem** documented in MEMORY.md. Agent recovered after seeing `available_variables` in error message.

- **Log excerpt:**
  ```
  2886: Tool: custom_operation({'source_labels': ['PSP_B_mag_val', 'PSP_SWP_SPI_SF00_L3_MOM.SUN_DIST'],
                                 'pandas_code': "... df_B_mag_val.loc[t_start:t_end] ..."})
  2889: WARNING | Tool result: custom_operation -> error: Execution error:
                  NameError: name 'df_B_mag_val' is not defined
  2894: result: {'available_variables': ['df_PSP_B_mag_val', 'df_SUN_DIST', 'df']}

  # Agent corrected in next attempt:
  2897: Tool: custom_operation({..., 'pandas_code': "... df_PSP_B_mag_val.loc[t_start:t_end] ..."})
  ```

- **Probable cause:**
  1. Custom operation sandbox injects variables as `df_{sanitized_label}`, but LLM uses original label
  2. This is a **known issue** per MEMORY.md (8+ occurrences in previous analysis)
  3. DataOps agent prompt doesn't explain variable naming convention clearly

- **Suggested fix:**
  1. **Immediate:** Update DataOps system prompt with explicit variable naming rules and examples
  2. **Short-term:** Add AST rewriter to auto-correct variable names before execution
  3. **Medium-term:** Change sandbox to inject simple names like `df` for single-source, `df_primary`/`df_secondary` for dual-source
  4. **Long-term:** Support multi-source operations with explicit namespace (e.g., `sources={'B': 'PSP_B_mag_val', 'R': 'SUN_DIST'}`)

- **Related files:** `agent/data_ops_agent.py`, `data_ops/custom_ops.py`

### Issue 6: Excessive Time Range Updates
- **Severity:** P1 — High
- **Log source:** Throughout session (13 occurrences)
- **Description:** Agent called `manage_plot({'action': 'set_time_range', ...})` **13 times** in 18 minutes. This suggests:
  1. Plot doesn't retain time range between updates
  2. Agent re-sets range after every `plot_data` call
  3. Wasted tool calls (each requires LLM round-trip)

- **Probable cause:**
  1. Visualization agent doesn't track current plot state (range, scale, labels)
  2. Agent defensively re-sets range to avoid "wrong range" errors
  3. User switching between 2024 and 2025 PSP encounters triggered multiple resets

- **Suggested fix:**
  1. **Immediate:** Visualization agent should track plot state in memory (current range, panels, etc.)
  2. **Short-term:** Only call `set_time_range` if requested range differs from current
  3. **Medium-term:** Merge `set_time_range` into `plot_data` as optional parameter
  4. **Performance impact:** 13 unnecessary tool calls = ~10-15 seconds wasted + API quota

- **Related files:** `agent/visualization_agent.py`, `rendering/plotly_renderer.py`

## Medium Priority Issues (P2)

### Issue 7: Wrong Parameter Name Attempted (V1800 vs V)
- **Severity:** P2 — Medium
- **Log source:** Lines 189-196
- **Description:** OMNI agent tried to fetch `V1800` from `OMNI2_H0_MRG1HR` dataset, but actual parameter is `V` (velocity). Agent saw error with full list of available variables and corrected.

- **Log excerpt:**
  ```
  189: Tool call: fetch_data({'time_range': '2026-01-12 to 2026-02-11',
                               'dataset_id': 'OMNI2_H0_MRG1HR',
                               'parameter_id': 'V1800'})
  195: WARNING | Tool result: fetch_data -> error: Variable 'V1800' not found in
                  omni2_h0_mrg1hr_20260101_v01.cdf. Available: [..., 'V', ...]
  ```

- **Probable cause:**
  1. LLM confused hourly dataset parameter naming with 1-minute dataset (`OMNI_HRO2_1MIN` has timestamped params)
  2. Agent didn't call `list_parameters` before `fetch_data`

- **Suggested fix:**
  1. **Short-term:** Mission agents should always call `list_parameters` before first fetch attempt
  2. **Medium-term:** Add parameter name validation to catalog

- **Related files:** `agent/mission_agent.py`, `knowledge/catalog.py`

### Issue 8: Cadence Mismatch Not Auto-Handled
- **Severity:** P2 — Medium
- **Log source:** Lines 2886-2921 (multiple resampling attempts)
- **Description:** Agent manually wrote resampling code 3 times to align `SUN_DIST` (1.7s cadence, 295,924 points) to `B_mag` (1 min cadence, 37,482 points). This is a common operation that should be automated.

- **Probable cause:**
  1. No built-in cadence alignment in multi-source `custom_operation`
  2. Agent tries different approaches: `resample().mean()`, `reindex()`, `reindex(method='nearest')`
  3. Each attempt is a full LLM round-trip

- **Suggested fix:**
  1. **Short-term:** Add `align_cadence` parameter to `custom_operation` (e.g., `align_cadence='1min'` or `align_cadence='primary'`)
  2. **Medium-term:** Auto-detect cadence mismatch and log INFO with alignment suggestion
  3. **Long-term:** Support temporal join operations declaratively

- **Related files:** `data_ops/custom_ops.py`, `agent/data_ops_agent.py`

## Low Priority Issues (P3)

### Issue 9: Dataset Availability Clamping Messages Not Surfaced to User
- **Severity:** P3 — Low
- **Log source:** Lines 158, 167, 191, etc. (multiple)
- **Description:** User requested 2026-01-12 to 2026-02-11 but data was clamped to available range (e.g., 2026-01-31 for OMNI). Agent logs DEBUG message but doesn't inform user of the adjustment.

- **Log excerpt:**
  ```
  158: DEBUG | [DataOps] Time range adjusted for OMNI_HRO2_1MIN:
              Requested range partially outside available data for 'OMNI_HRO2_1MIN'
              (available: 1995-01-01 to 2026-01-31). Clamped to 2026-01-12 to 2026-01-31.
  ```

- **Probable cause:**
  1. Availability clamping is silent (DEBUG level)
  2. Agent doesn't relay adjustment to user in final response
  3. User may expect full month of data but only gets partial

- **Suggested fix:**
  1. **Short-term:** Log at INFO level when clamping >10% of requested range
  2. **Medium-term:** Include "Data availability: 2026-01-12 to 2026-01-31 (requested to 02-11, adjusted)" in agent response
  3. **User impact:** Low (data still fetched, just shorter range)

- **Related files:** `data_ops/fetch.py`, `agent/core.py`

## Patterns & Trends

### Error Cascades
1. **Time range cascade:** Wrong SUN_DIST time range → all-NaN normalization → 3 retry attempts → manual fix
2. **Label cascade:** Wrong velocity component suffix → 2 failed plot attempts → sub-agent stops → user sees error

### Common Agent Behaviors
1. **Defensive time range setting:** Agent calls `set_time_range` before almost every plot update
2. **Trial-and-error parameter naming:** Tries `_0`, `_x`, `_1` suffixes without checking available labels
3. **Post-success verification:** After successful fetch, agent often calls `list_fetched_data` (wasted call)
4. **LLM-generated code iteration:** Average 2-3 attempts per `custom_operation` due to variable naming issues

### Tool Call Efficiency
- **Total calls:** 222
- **Estimated waste:** ~30-40 calls (post-success verification, duplicate time range sets, label guessing)
- **Efficiency:** ~82-85% (could be improved to 95%+ with fixes above)

## Recommendations

### Immediate Actions (P0)
1. **Fix contradictory error reporting** (Issue 2) — this is a data integrity risk
2. **Add time overlap validation** to `custom_operation` (Issue 1)
3. **Log WARNING when computed result has 0 points** (Issue 1)

### Short-Term (P1 - Within 1 Week)
1. **Add mission launch date validation** before CDAWeb fetch (Issue 3)
2. **Require `list_fetched_data` call** before first visualization attempt (Issue 4)
3. **Update DataOps prompt** with explicit variable naming rules (Issue 5)
4. **Add plot state tracking** to visualization agent (Issue 6)

### Medium-Term (P2 - Within 1 Month)
1. **Implement label versioning** with time ranges (Issue 1, long-term fix)
2. **Add fuzzy label matching** to suggest alternatives (Issue 4)
3. **Create declarative cadence alignment** tool (Issue 8)
4. **Surface data clamping** to user in response (Issue 9)

### Long-Term (Architecture)
1. **Multi-source custom operations redesign** with explicit namespace (Issue 5)
2. **Temporal join operations** as first-class tool (Issue 8)
3. **Plot state persistence** across sub-agent calls (Issue 6)

## Appendix: Raw Error Summary

| # | Timestamp | Level | Module | Message (truncated) |
|---|-----------|-------|--------|---------------------|
| 1 | 21:16:21 | WARNING | fetch_data | Variable 'V1800' not found in omni2_h0_mrg1hr_20260101_v01.cdf |
| 2 | 21:20:10 | WARNING | fetch_data | No data available for 'PSP_FLD_L2_MAG_RTN_1MIN' in the requested period. Dataset covers 2018-10-02 to 2025-07-31. Try a different dataset or adjust your time range. |
| 3 | 21:24:07 | WARNING | plot_data | Label 'PSP_SWP_SPI_SF00_L3_MOM.VEL_RTN_SUN_0' not found in memory |
| 4 | 21:24:09 | WARNING | plot_data | Label 'PSP_SWP_SPI_SF00_L3_MOM.VEL_RTN_SUN_x' not found in provided entries |
| 5 | 21:24:09 | WARNING | delegate_to_visualization | Sub-agent failed. Errors: plot_data: Label 'PSP_SWP_SPI_SF00_L3_MOM.VEL_RTN_SUN_0' not found in memory; plot_data: Label 'PSP_SWP_SPI_SF00_L3_MOM.VEL_RTN_SUN_x' not found in provided entries |
| 6 | 21:33:13 | WARNING | custom_operation | Execution error: Execution error: NameError: name 'df_B_mag_val' is not defined |
| 7 | 21:33:30 | WARNING | delegate_to_data_ops | Sub-agent failed. Errors: custom_operation: Execution error: Execution error: NameError: name 'df_B_mag_val' is not defined |

## Session Metadata

- **Model:** gemini-3-flash-preview (planner, sub-agents)
- **Duration:** 18 minutes 11 seconds
- **User turns:** ~8-10 (inferred from conversation flow)
- **Data fetched:** 16 labels (OMNI, Wind, PSP datasets)
- **Plots created:** 4-5 multi-panel figures
- **Final outcome:** Successful 4-panel PSP Encounter 24 plot with normalized B-field
